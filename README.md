# TS-Bench

## Overview

TS-Bench is a time-series benchmark evaluation system using an Agent-to-Agent (A2A)
architecture. The **green agent** ([ts_task_agent.py]) manages task distribution and
evaluation for time-series forecasting and generation tasks.

## Green Agent Workflow

The green agent (`TSTaskAgent`) roughly follows these steps:

**Trigger**: Receive `EvalRequest` with `task_type` (no results)

**Process**:
1. Validate task type ("time-series-forecasting" or "time-series-generation")
2. Retrieve all tasks of that type from `TaskBank`
3. Generate presigned S3 URLs for task data and evaluation functions
4. For each task:
  - Generate a text task instruction
  - Send task instructions to the Purple agent
  - Check and load the agents prediction data
  - Apply test metrics to the prediction data, and score the task
5. Once all the tasks are complete, aggregate the scores with weightings
6. Generate LLM-based feedback (Optional)
7. Complete the assessment

**Important**: Evaluation compares predictions generated by **purple agents** against ground truth.
The current `TaskAgent` pipeline assumes results are received from purple agents after they process
the assigned tasks.

## Metrics

### Forecasting Tasks
- **Primary**: RMSE (Root Mean Square Error)
- Secondary: MAE, Quantile Loss

### Generation Tasks
- **Primary**: SigW1 (Signature Wasserstein-1)
- Secondary: Auto-correlation, Cross-correlation

## Developers

## Installation

Dependencies can be installed with [poetry](https://python-poetry.org/) by running

```commandline
poetry install
```

which will create a virtual environment in the repo at `.venv` which can
be activated with

```commandline
source .venv/bin/activate
```

## Running

Run an example scenario locally using

```commandline
python -m ts_bench.run_scenario scenario.toml
```

## Developers

### Code Checks

- Linting/formatting can be using pre-commit
  ```commandline
  pre-commit run --all-files
  ```
