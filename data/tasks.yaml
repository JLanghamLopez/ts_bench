-
  task_id: crypto_forecasting
  name: Crypto Market Intraday Log-Return Forecasting
  task_type: time-series-forecasting
  difficulty: Intermediate
  description: |
    Task: Crypto Market Intraday Log-Return Forecasting

    **1. Task Overview**

    Cryptocurrency markets operate continuously without circuit breakers or overnight closures.
    This 24/7 environment, together with rapidly changing liquidity conditions, leads to pronounced
    short-horizon volatility and shifting dependence structures across assets. Reliable intraday
    forecasting is therefore both challenging and practically important for risk monitoring, hedging,
    and algorithmic decision-making.

    This task evaluates a model’s ability to forecast multivariate intraday log-return trajectories
    for a small set of highly liquid cryptocurrencies. Participants must predict the near-future evolution
    of hourly log-returns, capturing volatility dynamics and cross-asset relationships under relatively
    stable macroeconomic conditions.

    **2. Task Description**

    Participants are required to build and train a forecasting model that predicts the next 4 hourly
    log-return steps for three major cryptocurrencies, conditioned on the preceding 20 hours of observed
    log-returns.

    Each data sample represents one 24-hour window of hourly log-returns observed simultaneously across
    the three assets. For forecasting, each 24-hour trajectory is split into an input context window
    consisting of the first 20 hourly time steps, and a prediction target horizon consisting of the
    final 4 hourly time steps.

    Models should learn short-horizon temporal patterns (e.g., volatility clustering), handle noisy
    return dynamics, and preserve cross-asset dependence in the forecast horizon. Any forecasting
    approach may be used, including classical time-series models, machine learning methods, deep
    learning sequence models, or hybrid approaches, provided that the outputs conform exactly to
    the required format.

    **3. Dataset**

    The dataset consists of historical hourly log-return data for three of the most actively traded
    cryptocurrencies, spanning multiple years. To reduce the impact of extreme market regimes, periods
    associated with the COVID-19 crisis and large-scale quantitative easing have been excluded.
    The time series are segmented into overlapping 24-hour samples using a rolling window approach.

    For the forecasting task, participants are provided with the following pre-split NumPy datasets:
    Training inputs: train_X.npy, shape [7150, 20, 3]
    Training targets: train_Y.npy, shape [7150, 4, 3]
    Test inputs: test_X.npy, shape [1787, 20, 3]

    A held-out test target set (corresponding to the final 4 hours) is used for evaluation and is not
    provided to participants. Final ranking is based solely on performance on this held-out test set
    using all evaluation metrics.

    **4. Evaluation**

    Forecast performance is evaluated using the following metrics:

    - RMSE: Root mean squared error measuring overall forecast accuracy.
    - MAE: Mean absolute error providing a stable magnitude-based measure.
    - MAPE: Mean absolute percentage error offering a scale-normalised comparison.

    Evaluation code for all metrics will be provided.

    **5. Submission**

    Participants must return its forecasts as a JSON-serialized Python object (nested lists),
    representing the prediction output array. The array must contain model forecasts corresponding to
    the test inputs and must have the shape [1787, 4, 3].

    **6. Difficulty Level**

    Difficulty: Intermediate
  data_urls:
    train_x: https://tsbench.blob.core.windows.net/ts-bench-data/crypto_forecasting/train_X.npy
    train_y: https://tsbench.blob.core.windows.net/ts-bench-data/crypto_forecasting/train_Y.npy
    test_x: https://tsbench.blob.core.windows.net/ts-bench-data/crypto_forecasting/test_X.npy
  eval_url: https://github.com/JLanghamLopez/ts_bench/blob/main/src/ts_bench/agents/ts_task_agent/eval_forecasting.py?raw=true
  output_shape: [1787, 4, 3]
  ground_truth_file: crypto_forecasting.npy
-
  task_id: equity_forecasting
  name: Short-Horizon Forecasting of U.S. Equity Return–Volatility Dynamics
  task_type: time-series-forecasting
  difficulty: Easy
  description: |
    Task: Short-Horizon Forecasting of U.S. Equity Return–Volatility Dynamics

    **1. Task Overview**

    Financial time series are characterised by non-stationarity, heavy tails, and complex
    cross-asset interactions. Even under regular market conditions, forecasting short-horizon
    dynamics of returns and volatility remains challenging due to low signal-to-noise ratios
    and evolving dependence structures.

    This task focuses on short-horizon forecasting of multivariate financial time series under
    normal market conditions. Participants are asked to predict the near-future evolution of
    return and volatility dynamics for multiple correlated U.S. equities, using recent historical
    observations as input.

    **2. Task Description**

    In this competition, participants are challenged to construct a forecasting model that
    predicts the next trading day’s return–volatility vector given the recent history.

    Each sample represents the joint daily return and volatility dynamics of five correlated
    U.S. equities over a short horizon. For forecasting, each trajectory is split into:

    - an input context window consisting of the first 4 daily observations, and
    - a prediction target horizon consisting of the final 1 daily observation.

    Models are expected to learn short-horizon temporal dependencies and cross-equity
    relationships present in the data. Any forecasting approach may be used, including
    classical time-series models, machine learning regressors, deep learning sequence models,
    or hybrid approaches, provided that outputs conform to the required format.

    **3. Dataset**

    Participants are provided with preprocessed NumPy arrays corresponding to input–target
    splits derived from historical financial time series under normal market conditions.

    Training inputs: train_X.npy
    Shape: [870, 4, 10]
    Represents the first 4 daily observations of each training trajectory.

    Training targets: train_Y.npy
    Shape: [870, 1, 10]
    Represents the next-day return and volatility values to be forecasted.

    Test inputs: test_X.npy
    Shape: [217, 4, 10]
    Represents the first 4 daily observations of each test trajectory.

    Each time step contains 10 features corresponding to daily return and volatility measures
    for five correlated equities. The test targets are held out and used exclusively for evaluation.

    **4. Evaluation**

    Forecast performance is evaluated using the following metrics:

    - RMSE: Root mean squared error measuring overall forecast accuracy.
    - MAE: Mean absolute error providing a stable magnitude-based measure.
    - MAPE: Mean absolute percentage error offering a scale-normalised comparison.

    Evaluation code for all metrics will be provided.

    **5. Submission**

    Participants must return its forecasts as a JSON-serialized Python object (nested lists), representing the
    prediction array. The file must contain model forecasts corresponding to
    the test inputs and must have the shape of [217, 1, 10].

    **6. Difficulty Level**

    Difficulty: Easy
  data_urls:
    train_x: https://tsbench.blob.core.windows.net/ts-bench-data/equity_forecasting/train_X.npy
    train_y: https://tsbench.blob.core.windows.net/ts-bench-data/equity_forecasting/train_Y.npy
    test_x: https://tsbench.blob.core.windows.net/ts-bench-data/equity_forecasting/test_X.npy
  eval_url: https://github.com/JLanghamLopez/ts_bench/blob/main/src/ts_bench/agents/ts_task_agent/eval_forecasting.py?raw=true
  output_shape: [217, 1, 10]
  ground_truth_file: equity_forecasting.npy
-
  task_id: regime_switching_forecasting
  name: Regime-switching Financial Time-Series Forecasting
  task_type: time-series-forecasting
  difficulty: Advanced
  description: |
    Task: Regime-switching Financial Time-Series Forecasting

    **1. Task Overview**

    The limited availability of financial and economic data is a major bottleneck for the effective
    application of machine learning methods in finance. Forecasting models trained on financial time
    series must handle strong non-stationarity, low signal-to-noise ratios, and abrupt structural
    changes that often reflect regime shifts such as periods of market stress.

    Accurate short- to medium-horizon forecasting of multivariate price–volatility dynamics is
    important for risk management, scenario analysis, and trading. In regime-switching environments,
    models must remain robust under both stable and elevated-volatility episodes and should preserve
    cross-asset relationships rather than fitting only marginal trends.

    This task focuses on forecasting the near-future evolution of a multivariate financial system by
    learning from historical trajectories that implicitly contain multiple market regimes.

    **2. Task Description**

    In this competition, participants are challenged to construct a forecasting model that predicts
    the next two time steps of a multivariate financial time series given the preceding history.

    Each sample trajectory represents the joint evolution of price and volatility processes for two
    financial instruments over 20 time steps. For the forecasting task, each trajectory is split into:

    - an input context window of the first 18 time steps, and
    - a prediction target horizon of the final 2 time steps.

    Models are expected to learn medium-horizon temporal structure, handle regime-dependent dynamics
    (without explicit regime labels), and preserve cross-variable and cross-asset dependence in their
    forecasts. Any forecasting approach may be used, including classical time-series models, machine
    learning regressors, deep learning sequence models, or hybrid methods, provided that outputs conform
    to the required format.

    **3. Dataset**

    Participants will be provided with pre-split NumPy datasets derived from the original regime-switching
    trajectories. The original data consist of multivariate sample paths with shape [N, 20, 4], where each
    trajectory contains 20 time steps, and 4 channels corresponding to price and volatility variables for
    two financial instruments.

    For this forecasting task, the following the data are split into input–target pairs as follows:
    - Training inputs: train_X.npy with shape [20000, 18, 4]
      The first 18 time steps of each training trajectory.

    - Training targets: train_Y.npy with shape [20000, 2, 4]
      The final 2 time steps to be forecasted.
    - Test inputs: test_X.npy with shape [2000, 18, 4]
      The first 18 time steps of each test trajectory.

    A held-out test target set (corresponding to the final 2 time steps) is used for evaluation and is not
    provided to participants. Final ranking is based solely on performance on this held-out test set using
    all evaluation metrics.

    **4. Evaluation**

    Forecast performance is evaluated using the following metrics:

    - RMSE: Root mean squared error measuring overall forecast accuracy.
    - MAE: Mean absolute error providing a stable magnitude-based measure.
    - MAPE: Mean absolute percentage error offering a scale-normalised comparison.

    Evaluation code for all metrics will be provided.

    **5. Submission**

    Participants must return its forecasts as a JSON-serialized Python object (nested lists),
    representing the prediction array. The file must contain model forecasts corresponding to
    the test inputs and must have the shape [2000, 2, 4].

    A strong submission should:
    - Achieve low RMSE, MAE, and MAPE on the 2-day forecast horizon.
    - Produce stable forecasts without systematic drift or excessive noise.

    **6. Difficulty Level**

    Difficulty: Advanced

    Although the forecast horizon is short, the underlying trajectories exhibit regime-switching behaviour
    and heterogeneous volatility patterns. Successful models must generalise across both stable and stressed
    regimes and preserve multivariate dependence structures, making the task substantially more challenging
    than standard stationary forecasting benchmarks.
  data_urls:
    train_x: https://tsbench.blob.core.windows.net/ts-bench-data/regime_switching_forecasting/train_X.npy
    train_y: https://tsbench.blob.core.windows.net/ts-bench-data/regime_switching_forecasting/train_Y.npy
    test_x: https://tsbench.blob.core.windows.net/ts-bench-data/regime_switching_forecasting/test_X.npy
  eval_url: https://github.com/JLanghamLopez/ts_bench/blob/main/src/ts_bench/agents/ts_task_agent/eval_forecasting.py?raw=true
  output_shape: [2000, 2, 4]
  ground_truth_file: regime_switching_forecasting.npy
-
  task_id: crypto_generation
  name: Crypto Market Log-Return Simulation
  task_type: time-series-generation
  difficulty: Intermediate
  description: |
    Task: Crypto Market Log-Return Simulation

    **1. Task Overview**

    This task evaluates a model’s ability to generate multivariate intraday log-return trajectories over a 24-hour horizon
    for a small set of highly liquid cryptocurrencies. The objective is to model short-horizon return behaviour observed
    in continuous cryptocurrency markets, including volatility dynamics and cross-asset dependence, under relatively stable
    macroeconomic conditions.

    **2. Task Description**

    Participants are required to train a generative model that produces intraday log-return trajectories for three highly
    traded cryptocurrencies. Each data sample represents one trading day and consists of 24 consecutive hourly log-returns
    observed simultaneously across the three assets.

    The training data are constructed using a rolling window approach applied to historical market data. Each window is
    treated as an independent sample drawn from an unknown underlying distribution of daily return trajectories.
    The modelling objective is to learn this distribution and to generate new synthetic samples that are indistinguishable
    from real data in terms of their statistical and temporal properties.

    Any generative modelling approach may be used, including diffusion-based models, GANs, flow-based models, autoregressive
    generators, or other sequence-based methods. Regardless of the modelling choice, generated outputs must have the exact
    shape [24,3] and reflect realistic intraday behaviour, including variability over time and dependence between assets.

    **3. Dataset**

    The dataset consists of historical hourly log-return data for three of the most actively traded cryptocurrencies,
    spanning more than seven years. To reduce the impact of extreme market regimes, periods associated with the COVID-19
    crisis and large-scale quantitative easing have been excluded. The time series are segmented into overlapping 24-hour
    samples using a rolling window approach.

    Only the training dataset (train_log_return.npy) will be provided to participants, which has shape (7150, 24, 3).
    Final evaluation is performed on the held-out test set using all evaluation metrics.

    **4. Evaluation**

    Generated trajectories are evaluated by comparison with real test trajectories using the following metrics:

    - HistogramMetric: Measures the similarity between real and generated time series by comparing their empirical marginal distributions.
    - CrossCorrelationMetric:  Evaluates whether dependence structures across different dimensions of the time series are preserved.
    - AutoCorrelationMetric:  Assesses temporal dependence within individual time series components.

    Evaluation code for all metrics will be provided.

    **5. Submission**

    Participants must return 1787 generated multivariate time series samples as a JSON-serialized Python object (nested lists) with shape [1787, 24, 3].

    A strong submission should:
    - Achieve low discrepancy on HistogramMetric on the test set.
    - Preserve cross-asset dependence as measured by CrossCorrelationMetric.
    - Match short-horizon temporal behaviour reflected by AutoCorrelationMetric.
    - Produce stable trajectories without obvious artefacts.

    **6. Difficulty Level**

    Difficulty: Intermediate

    The task focuses on modelling short-horizon multivariate return dynamics for a small number of assets under
    relatively stable market conditions. While temporal and cross-sectional dependence must be captured, the
    reduced dimensionality and absence of regime extremes make the problem more accessible than large-scale,
    high-dimensional financial generative modelling tasks.
  data_urls:
    train: https://tsbench.blob.core.windows.net/ts-bench-data/crypto_generation/train.npy
  eval_url: https://github.com/JLanghamLopez/ts_bench/blob/main/src/ts_bench/agents/ts_task_agent/eval_generation.py?raw=true
  output_shape: [1787, 24, 3]
  ground_truth_file: crypto_generation.npy
-
  task_id: equity_generation
  name: Short-Horizon Generative Modelling of U.S. Equity Return–Volatility Dynamics
  task_type: time-series-generation
  difficulty: Easy
  description: |
    Task: Short-Horizon Generative Modelling of U.S. Equity Return–Volatility Dynamics

    **1. Task Overview**

    Financial time series often exhibit non-stationarity, heavy tails, and complex temporal dependence,
    making realistic data-driven modelling a challenging task. In many practical applications, the availability
    of high-quality financial data is limited, which restricts the performance of downstream machine learning models.
    Synthetic data generation offers a promising solution by enabling the creation of artificial time series that
    preserve the statistical characteristics of real data while mitigating data scarcity and privacy concerns.
    This task focuses on the unconditional generation of financial time series under regular market conditions.
    Participants are asked to develop generative models that can produce realistic multivariate financial time series
    reflecting normal market dynamics, without conditioning on explicit regime labels.

    **2. Task Description**

    In this competition, participants are challenged to construct and train an unconditional generative model capable of
    simulating synthetic financial time series that closely approximate the distribution of real data observed under
    normal market conditions.

    Each generated sample should represent the joint evolution of daily returns and volatility for multiple financial assets
    over a short time horizon. The objective is to reproduce realistic temporal dynamics and cross-asset relationships present
    in the training data.

    Any generative modelling approach may be used, including GANs, variational autoencoders, diffusion models, or other
    sequence-based generators, provided that the generated outputs match the required data format.

    **3. Dataset**

    The dataset consists of historical financial time series representing daily return and volatility dynamics under normal
    market conditions. All samples corresponding to crisis periods have been removed to focus exclusively on regular market
    behaviour. The time series represent the joint evolution of five correlated financial assets over a short horizon.
    Each sample corresponds to a fixed-length trajectory and is treated as an independent observation drawn from the underlying
    data-generating process.

    Only the training dataset will be provided to participants:
    File: train.npy
    Shape: [870, 5, 10]
    Description:
      - 870 sample trajectories
      - 5 time steps per trajectory (daily observations)
      - 10 features per time step, corresponding to return and volatility measures for the 5 assets

    Final evaluation is performed on the held-out test set using all evaluation metrics.

    **4. Evaluation**

    Generated trajectories are evaluated by comparing samples from the model to real test trajectories using the following metrics:

    - HistogramMetric: Measures the similarity between real and generated time series by comparing their empirical marginal distributions.
    - CrossCorrelationMetric: Evaluates whether dependence structures across different dimensions of the time series are preserved.
    - AutoCorrelationMetric: Assesses temporal dependence within individual time series components.

    Evaluation code for all metrics will be provided.

    **5. Submission**

    Participants must return 217 generated multivariate time series samples as a JSON-serialized Python object (nested lists) with shape [217, 5, 10].

    A strong submission should:
    - Achieve low discrepancy on HistogramMetric on the test set.
    - Preserve cross-equity dependence patterns.
    - Match short-term temporal behaviour observed in the data.
    - Produce stable trajectories without artefacts or mode collapse.

    **6. Difficulty Level**

    Difficulty: Easy
  data_urls:
    train: https://tsbench.blob.core.windows.net/ts-bench-data/equity_generation/train.npy
  eval_url: https://github.com/JLanghamLopez/ts_bench/blob/main/src/ts_bench/agents/ts_task_agent/eval_generation.py?raw=true
  output_shape: [217, 5, 10]
  ground_truth_file: equity_generation.npy
-
  task_id: regime_switching_generation
  name: Regime-switching Financial Time-Series Generation
  task_type: time-series-generation
  difficulty: Advanced
  description: |
    Task: Regime-switching Financial Time-Series Generation

    **1. Task Overview**

    The limited availability of financial and economic data is a major bottleneck for the effective application of
    machine learning methods in finance. High-fidelity synthetic data generation provides a promising approach to
    augment existing datasets while preserving statistical properties and protecting data privacy. Recent advances
    in generative modelling, including GANs, VAEs, and diffusion-based models, have shown strong potential in this area.

    Financial time series exhibit distinctive challenges, such as strong time heterogeneity, low signal-to-noise ratios,
    and abrupt structural changes. In particular, asset price and volatility dynamics often behave very differently
    during periods of market stress compared to economically stable regimes. These regime shifts are commonly associated
    with events such as financial crises, pandemics, or major policy interventions.

    This task focuses on developing generative models that can faithfully reproduce multivariate financial time series
    exhibiting regime-switching behaviour. Robust solutions are expected to capture both normal and high-volatility
    regimes and the transitions between them.

    **2. Task Description**

    In this competition, participants are challenged to construct a generative model capable of producing synthetic
    financial time series that closely mimic the joint distribution of price and volatility processes for multiple
    financial instruments.

    The training data consist of short multivariate trajectories that reflect different market regimes, including
    low-volatility and high-volatility episodes. These regimes are not explicitly labelled; instead, regime characteristics
    must be inferred implicitly from the observed dynamics. Participants may employ any generative modelling approach,
    including but not limited to GAN-based models, variational autoencoders, diffusion models, or other sequence-based
    generators. Generated samples should reproduce realistic temporal dynamics, cross-variable relationships, and
    regime-dependent behaviour observed in the real data.

    **3. Dataset**

    The participants will be provided with the training dataset (train.npy) It consists of 20,000 sample trajectories,
    each representing the joint evolution of price and volatility for two financial instruments over a fixed time horizon.

    Training Dataset shape: [20000, 20, 4]

    Interpretation:
    - 20 time steps per trajectory
    - 4 channels corresponding to price and volatility variables for the two assets

    The dataset exhibits heterogeneous dynamics arising from different market regimes, including periods of elevated
    volatility and more stable behaviour. No explicit regime labels are provided.

    Final ranking is based solely on performance on the held-out test set using all evaluation metrics.

    **4. Evaluation**

    Models will be evaluated by comparing generated trajectories to real test trajectories using three metrics:

    - HistogramMetric: Measures the similarity between real and generated time series by comparing their empirical marginal distributions.
    - CrossCorrelationMetric: Evaluates whether dependence structures across different dimensions of the time series are preserved.
    - AutoCorrelationMetric: Assesses temporal dependence within individual time series components.

    Evaluation metric code for all three metrics will be provided to participants.

    **5. Submission**

    Participants must submit their generated samples as a JSON-serialized Python object (nested lists) representing the
    synthetic time series array.

    The submission must have the following shape: [2000, 20, 4]

    A successful submission should:
    - Achieve low discrepancy on HistogramMetric on the test set.
    - Preserve cross-commodity temporal dependence patterns reflected by CrossCorrelationMetric.
    - Match temporal persistence and volatility characteristics measured by AutoCorrelationMetric.
    - Produce stable and realistic trajectories without obvious artefacts or mode collapse.

    **6. Difficulty Level**

    Difficulty: Advanced
  data_urls:
    train: https://tsbench.blob.core.windows.net/ts-bench-data/ground_truths/regime_switching_generation.npy
  eval_url: https://github.com/JLanghamLopez/ts_bench/blob/main/src/ts_bench/agents/ts_task_agent/eval_generation.py?raw=true
  output_shape: [2000, 20, 4]
  ground_truth_file: regime_switching_generation.npy
