[
    {
        "task_id": "commodity_forecast",
        "name": "Medium-Horizon Multivariate Forecasting of Commodity Log-Returns",
        "description": "Task: Medium-Horizon Multivariate Forecasting of Commodity Log-Returns\n\n**1. Task Overview**\n\nThis task evaluates a model\u2019s ability to forecast 5-day multivariate log-return sequences for nine major commodities, using the preceding 60 days of observations as input.  \nThe objective is to capture medium-term commodity-market dynamics influenced by seasonal behaviour, macroeconomic conditions, weather shocks, and cross-commodity linkages.\n\nTask Type: Forecasting  \nInput Shape: [60, 9] log-return sequences  \nTarget Shape: [5, 9] log-return sequences  \n\n**2. Task Description**\n\nParticipants must build a supervised forecasting model that takes as input 60 consecutive days of log-returns across the following commodities:\ngold, silver, copper, crude_oil_wti, crude_oil_brent, natural_gas, corn, wheat, soybeans.\n\nThe model must then predict the next 5 days of log-returns for the same nine assets.  \nEach supervised pair therefore consists of:\n- an input matrix of shape [60, 9],  \n- a target matrix of shape [5, 9].  \n\nThe forecasting problem requires capturing medium-horizon features such as:\n- persistent seasonal factors in energy and agricultural markets,  \n- macroeconomic news effects that propagate slowly across commodities,  \n- volatility clustering within metals and energy,  \n- cross-commodity spillovers (e.g., oil-price effects on agricultural inputs).\n\nAny forecasting architecture may be used, such as transformer models, sequence-to-sequence architectures, temporal convolutional networks, RNN-based models, or regression-style baselines, provided that outputs match the expected [5, 9] structure.\n\n**3. Dataset**\n\nThe dataset contains daily settlement prices converted into log-returns to normalize scale and provide a stationary representation across commodities with large differences in price levels.  \nEach supervised sample consists of a 60-day input window and a 5-day forecast horizon, offering roughly three months of information for predicting the subsequent week.\n\nThe dataset is split into:\n- Train set  \n- Validation set  \n- Test set  \n\nParticipants develop and tune models using the train and validation splits.  \nFinal evaluation and ranking rely exclusively on the test set.\n\n**4. Evaluation**\n\nForecast performance is measured using three metrics suited to multivariate commodity prediction:\n\n- RMSE  \n  Root mean squared error capturing magnitude-based forecast accuracy.\n\n- MAE  \n  Mean absolute error providing a robust error measure less affected by large spikes common in commodity markets.\n\n- QuantileLoss  \n  Pinball loss evaluating the accuracy of predictive distributions at chosen quantiles, providing insight into a model\u2019s ability to capture asymmetric risks and tail behaviours.\n\nRMSE and MAE assess overall magnitude accuracy,  \nwhile QuantileLoss evaluates probabilistic and risk-sensitive forecast quality.\n\n**5. Success Criteria**\n\nA strong submission should:\n- Achieve low RMSE, MAE, and QuantileLoss scores on the 5-day prediction horizon.  \n- Capture medium-term inter-commodity relationships, volatility regimes, and structural dependencies.  \n- Produce forecasts without excessive noise, drift, or systematic bias.  \n- Demonstrate stability across commodities with varied behaviours (e.g., energy vs. metals vs. agricultural assets).\n\n**6. Difficulty Level**\n\nDifficulty: Advanced\n\nCommodity markets feature complex medium-horizon dynamics, structural breaks, seasonal patterns, and diverse shock propagation mechanisms.  \nEffective forecasting across nine commodities requires modelling both temporal and cross-sectional structure at a relatively long input horizon.",
        "task_type": "Forecasting",
        "difficulty": "Advanced",
        "data_s3_key": "tasks/commodity_forecast/data/",
        "eval_fn_s3_key": "tasks/commodity_forecast/evaluation/"
    },
    {
        "task_id": "commodity_generative",
        "name": "Multivariate Generative Modelling of Commodity Log-Return Trajectories",
        "description": "Task: Multivariate Generative Modelling of Commodity Log-Return Trajectories\n\n**1. Task Overview**\n\nThis task evaluates a model\u2019s ability to generate realistic 60-day multivariate log-return trajectories for nine major commodities.\nThe goal is to reproduce medium-term market behaviour, including volatility patterns, cross-market co-movements, and risk-sensitive characteristics of the joint distribution.\n\nTask Type: Generative modelling  \nTrajectory Shape: [60, 9] log-return sequences  \n\n**2. Task Description**\n\nParticipants must train a generative model capable of producing realistic 60-day paths of daily log-returns across the following commodities:\ngold, silver, copper, crude_oil_wti, crude_oil_brent, natural_gas, corn, wheat, and soybeans.\n\nEach data sample is a window of 60 consecutive daily log-returns across these nine commodities.\nThe trained model should be able to generate new trajectories with the same shape and comparable statistical and temporal properties to those observed in the real data.\n\nAny generative architecture may be used (for example, diffusion models, GANs, normalizing flows, or signature-based models), provided that the generated output matches the required dimensions and format.\n\n**3. Dataset**\n\nThe dataset consists of log-return time series constructed from daily settlement prices for the nine commodities.\nThe series have been segmented into overlapping windows using a 60-day window and a stride of 5 days, resulting in [60, 9] log-return trajectories that capture medium-term dynamics.\n\nPredefined splits are provided:\n- Train set  \n- Validation set  \n- Test set  \n\nParticipants should use the train and validation sets for model training and tuning.\nFinal ranking will be based solely on performance on the held-out test set.\n\n**4. Evaluation**\n\nModels will be evaluated by comparing generated trajectories to real test trajectories using three metrics:\n\n- SigW1Metric  \n  A path-based metric that measures discrepancies between real and generated trajectory distributions using expected signatures.\n\n- CrossCorrelationMetric  \n  Compares lagged cross-correlations between commodities, assessing whether inter-market temporal dependencies are preserved.\n\n- VARMetric  \n  Compares Value-at-Risk (VaR) statistics between real and generated data, assessing how well tail-risk behaviour is reproduced.\n\nSigW1Metric serves as the primary ranking metric.\nCrossCorrelationMetric and VARMetric provide complementary information on temporal dependence and tail-risk alignment.\n\n**5. Success Criteria**\n\nA successful submission should:\n- Achieve low discrepancy on SigW1Metric on the test set.  \n- Preserve cross-commodity temporal dependence patterns reflected by CrossCorrelationMetric.  \n- Match the tail-risk characteristics of the real data as measured by VARMetric.  \n- Produce stable and realistic trajectories without obvious artefacts or mode collapse.\n\n**6. Difficulty Level**\n\nDifficulty: Advanced\n\nThis task requires modelling multivariate temporal dynamics, cross-asset relationships, and non-Gaussian risk characteristics within a generative modelling framework.",
        "task_type": "Generative modelling",
        "difficulty": "Advanced",
        "data_s3_key": "tasks/commodity_generative/data/",
        "eval_fn_s3_key": "tasks/commodity_generative/evaluation/"
    },
    {
        "task_id": "crypto_forecast",
        "name": "Short-Horizon Multivariate Forecasting of Cryptocurrency Log-Returns",
        "description": "Task: Short-Horizon Multivariate Forecasting of Cryptocurrency Log-Returns\n\n**1. Task Overview**\n\nThis task evaluates a model\u2019s ability to forecast 6-hour multivariate log-return sequences for ten major cryptocurrencies, using the preceding 24 hours of market activity as input.  \nThe objective is to predict short-term return dynamics shaped by rapid sentiment shifts, liquidity fragmentation, global timezone transitions, and the continuous 24/7 nature of crypto trading.\n\nTask Type: Forecasting  \nInput Shape: [24, 10] log-return sequences  \nTarget Shape: [6, 10] log-return sequences  \n\n**2. Task Description**\n\nParticipants must construct a supervised forecasting model that takes as input 24 consecutive hours of log-returns across the following cryptoassets:\nADAUSDT, BNBUSDT, BTCUSDT, DOTUSDT, ETHUSDT, LINKUSDT, LTCUSDT, SOLUSDT, XLMUSDT, XRPUSDT.\n\nThe model must then generate predictions for the subsequent 6 hours of log-returns for the same ten assets.  \nEach supervised pair consists of:\n- an input matrix of shape [24, 10],  \n- a target matrix of shape [6, 10].  \n\nThe forecasting challenge requires modeling fine-scale crypto-market characteristics, including:\n- abrupt volatility bursts,  \n- rapid cross-asset contagion during news events,  \n- timezone-driven liquidity shifts,  \n- short-lived but highly nonlinear return dependencies.\n\nAny forecasting architecture may be used, such as transformer models, attention-based sequence-to-sequence models, RNN or LSTM variants, temporal convolutional networks, or regression-oriented baselines, as long as the generated output matches the required [6, 10] structure.\n\n**3. Dataset**\n\nThe dataset is derived from several years of hourly price data for major cryptocurrency markets.  \nRaw prices are converted into log-returns to normalise scale and isolate proportional changes across assets with widely varying price levels.\n\nEach supervised sample pairs a 24-hour observation window with a 6-hour prediction horizon, reflecting:\n- the continuous, global trading cycle of crypto markets,  \n- the high-frequency nature of short-term return behaviour,  \n- the need to forecast imminent volatility in rapidly evolving environments.\n\nThe dataset includes:\n- Train set  \n- Validation set  \n- Test set  \n\nParticipants must train and tune models using the train and validation sets.  \nFinal leaderboard evaluation is based solely on performance on the test split.\n\n**4. Evaluation**\n\nThree metrics are used to measure short-term crypto forecasting performance:\n\n- RMSE  \n  Root mean squared error measuring absolute magnitude accuracy across all assets and forecast steps.\n\n- MAE  \n  Mean absolute error providing a robust evaluation of return-forecast accuracy, particularly important in markets prone to extreme spikes.\n\n- QuantileLoss  \n  Pinball loss assessing probabilistic forecast quality at specified quantiles, capturing asymmetry, tail risk, and sharp volatility bursts.\n\nRMSE and MAE evaluate numerical accuracy,  \nwhile QuantileLoss measures distributional and risk-sensitive forecast performance.\n\n**5. Success Criteria**\n\nA strong submission should:\n- Achieve low RMSE, MAE, and QuantileLoss over the 6-hour prediction horizon.  \n- Capture rapid cross-asset dependencies and short-lived structural patterns typical of crypto markets.  \n- Produce forecasts that are stable, well-calibrated, and free from pathological drift or oversmoothing.  \n- Demonstrate robustness across assets with highly heterogeneous volatility and liquidity characteristics.\n\n**6. Difficulty Level**\n\nDifficulty: Advanced\n\nCrypto markets exhibit extreme volatility, continuous trading, rapid structural shifts, and strong inter-asset contagion.  \nProducing accurate short-horizon multivariate forecasts requires models capable of handling nonlinear dynamics, high-frequency behaviour, and complex cross-asset interactions within a condensed forecast window.",
        "task_type": "Forecasting",
        "difficulty": "Advanced",
        "data_s3_key": "tasks/crypto_forecast/data/",
        "eval_fn_s3_key": "tasks/crypto_forecast/evaluation/"
    },
    {
        "task_id": "crypto_generative",
        "name": "Multivariate Generative Modelling of 24-Hour Cryptocurrency Log-Return Cycles",
        "description": "Task: Multivariate Generative Modelling of 24-Hour Cryptocurrency Log-Return Cycles\n\n**1. Task Overview**\n\nThis task evaluates a model\u2019s ability to generate realistic 24-step multivariate log-return sequences for a basket of major cryptocurrencies.  \nThe objective is to capture the distinctive dynamics of digital-asset markets, including high-frequency volatility bursts, cross-asset co-movement patterns, global timezone effects, and rapid sentiment-driven fluctuations.\n\nTask Type: Generative modelling  \nTrajectory Shape: [24, 10] log-return sequences  \n\n**2. Task Description**\n\nParticipants must develop a generative model capable of producing realistic 24-hour sequences of hourly log-returns across the following cryptoassets:\nADAUSDT, BNBUSDT, BTCUSDT, DOTUSDT, ETHUSDT, LINKUSDT, LTCUSDT, SOLUSDT, XLMUSDT, XRPUSDT.\n\nEach data sample is a 24-step rolling window of hourly log-returns over ten cryptocurrency pairs.  \nThe model should be able to generate synthetic 24-hour return cycles that reproduce the prominent features of crypto markets, such as sharp jumps following news releases, liquidity-driven regime shifts, rapid inter-asset transmission of shocks, and persistent short-horizon volatility patterns.\n\nAny generative architecture may be used, including diffusion models, GANs, flow-based models, autoregressive generators, or signature-based models, as long as the generated trajectories have the correct [24, 10] structure.\n\n**3. Dataset**\n\nThe dataset is derived from hourly price data covering several years of major cryptocurrency trading activity.  \nRaw prices are transformed into log-returns to normalize scale across assets and highlight proportional changes.\n\nThe time series is segmented into windows of length 24 using a stride of 4 hours.  \nThis design captures:\n- Full day-long segments reflecting the 24/7 nature of crypto markets,  \n- Overlapping windows sufficient for dense learning,  \n- Short-horizon behaviour including volatility clustering and rapid sentiment propagation.\n\nThe dataset contains:\n- Train set  \n- Validation set  \n- Test set  \n\nParticipants use the train and validation sets to build and tune models.  \nFinal evaluation and leaderboard ranking are based solely on the test set.\n\n**4. Evaluation**\n\nGenerated output is compared to real crypto return sequences using three metrics:\n\n- CrossCorrelationMetric  \n  Measures lagged cross-asset correlation behaviour, ensuring the model captures instantaneous and short-lag co-movements across cryptoassets.\n\n- AutoCorrelationMetric  \n  Assesses the autocorrelation structure of individual crypto return series, reflecting short-range dependencies, volatility dynamics, and hourly return characteristics.\n\n- SigW1Metric  \n  A path-based distance evaluating the discrepancy between real and generated return paths using expected signatures, capturing higher-order temporal structure and joint trajectory behaviour.\n\nCrossCorrelationMetric captures cross-asset structure,  \nAutoCorrelationMetric captures intra-asset temporal dependencies,  \nand SigW1Metric provides a comprehensive path-level assessment.\n\n**5. Success Criteria**\n\nA strong submission should:\n- Achieve low discrepancy on SigW1Metric when generating 24-hour crypto return paths.  \n- Preserve realistic inter-asset correlation patterns as assessed by CrossCorrelationMetric.  \n- Reproduce hourly autocorrelation and volatility patterns indicated by AutoCorrelationMetric.  \n- Generate stable trajectories that avoid artefacts such as constant paths, unrealistic spikes, mode collapse, or excessively smooth behaviour.\n\n**6. Difficulty Level**\n\nDifficulty: Advanced\n\nCryptocurrency markets exhibit pronounced non-stationarity, high volatility, rapid structural shifts, and strong cross-asset connectivity.  \nAccurately modelling these properties within a generative framework requires robust handling of multivariate short-horizon dynamics, non-Gaussian features, and rapidly evolving dependence structures across assets.",
        "task_type": "Generative modelling",
        "difficulty": "Advanced",
        "data_s3_key": "tasks/crypto_generative/data/",
        "eval_fn_s3_key": "tasks/crypto_generative/evaluation/"
    },
    {
        "task_id": "currency_forecast",
        "name": "Multivariate Forecasting of Major FX Log-Return Dynamics",
        "description": "Task: Multivariate Forecasting of Major FX Log-Return Dynamics\n\n**1. Task Overview**\n\nThis task evaluates a model\u2019s ability to forecast 5-day multivariate log-return sequences for seven major foreign-exchange pairs, using the preceding 40 days of market behaviour as input.  \nThe objective is to capture medium-horizon FX dynamics shaped by monetary-policy shifts, macroeconomic announcements, and cross-currency interactions.\n\nTask Type: Forecasting  \nInput Shape: [40, 7] log-return sequences  \nTarget Shape: [5, 7] log-return sequences  \n\n**2. Task Description**\n\nParticipants must develop a supervised forecasting model that takes as input 40 days of log-returns across the following currency pairs:\nEUR_USD, GBP_USD, USD_JPY, USD_CNY, AUD_USD, USD_CHF, USD_CAD.\n\nThe model must then produce a forecast for the next 5 days of log-returns for the same seven FX pairs.  \nEach data sample therefore contains:\n- an input matrix of shape [40, 7],  \n- a target matrix of shape [5, 7].  \n\nThe forecasting challenge requires learning medium-horizon temporal relationships such as:\n- interest-rate\u2013driven adjustments across currency pairs,  \n- policy divergence patterns between central banks,  \n- cross-currency risk transmission,  \n- regime shifts in global risk sentiment.\n\nAny forecasting model is permitted, including transformer models, recurrent architectures, sequence-to-sequence networks, temporal convolutional models, or regression-based baselines, provided that produced outputs match the required [5, 7] structure.\n\n**3. Dataset**\n\nThe dataset is constructed from daily foreign-exchange rates converted into log-returns to normalize scale and focus on incremental exchange-rate movements.  \nEach supervised sample pairs a 40-day input window with a 5-day prediction horizon, capturing nearly two months of FX dynamics prior to forecasting the next week.\n\nThe dataset includes:\n- Train set  \n- Validation set  \n- Test set  \n\nParticipants must use the train and validation sets for model development.  \nFinal ranking is based solely on performance on the test set.\n\n**4. Evaluation**\n\nForecast accuracy is assessed using three metrics well suited to multivariate FX prediction:\n\n- RMSE  \n  Root mean squared error evaluating magnitude accuracy of predicted log-returns.\n\n- MAE  \n  Mean absolute error providing a stable measure of forecast accuracy less sensitive to outliers.\n\n- MAPE  \n  Mean absolute percentage error measuring relative forecast error, particularly useful for FX returns where proportional deviations are informative.\n\nRMSE and MAE measure absolute magnitude accuracy,  \nwhile MAPE assesses proportional prediction quality across currency pairs.\n\n**5. Success Criteria**\n\nA strong submission should:\n- Achieve low RMSE, MAE, and MAPE over the 5-day prediction horizon.  \n- Produce stable, well-calibrated forecasts without drift or excessive noise.  \n- Capture medium-horizon cross-currency interactions, volatility patterns, and regime behaviour reflected in the input sequences.\n\n**6. Difficulty Level**\n\nDifficulty: Intermediate to Advanced\n\nModels must learn a rich combination of macroeconomic drivers, cross-currency dependencies, and medium-horizon temporal structure to generate accurate forecasts across major FX pairs.",
        "task_type": "Forecasting",
        "difficulty": "Intermediate to Advanced",
        "data_s3_key": "tasks/currency_forecast/data/",
        "eval_fn_s3_key": "tasks/currency_forecast/evaluation/"
    },
    {
        "task_id": "currency_generative",
        "name": "Multivariate Generative Modelling of High-Frequency FX Log-Return Sequences",
        "description": "Task: Multivariate Generative Modelling of High-Frequency FX Log-Return Sequences\n\n**1. Task Overview**\n\nThis task evaluates a model\u2019s ability to generate realistic 24-step multivariate log-return sequences for seven major foreign-exchange pairs.  \nThe objective is to reproduce short-horizon FX market behaviour, including cross-currency co-movements, interest-rate\u2013driven adjustments, macroeconomic shock responses, and volatility clustering.\n\nTask Type: Generative modelling  \nTrajectory Shape: [24, 7] log-return sequences  \n\n**2. Task Description**\n\nParticipants must build a generative model capable of producing realistic 24-step sequences of daily log-returns across the following FX pairs:\nEUR_USD, GBP_USD, USD_JPY, USD_CNY, AUD_USD, USD_CHF, USD_CAD.\n\nEach sample is a sequence of 24 consecutive log-return observations across the seven currency pairs.  \nThe model must learn to generate synthetic sequences that display realistic joint dynamics, including synchronous cross-currency movements, idiosyncratic deviations associated with policy differentials, and short-horizon volatility patterns typical of FX markets.\n\nThe dataset emphasizes local temporal behaviour and short-run dependencies.  \nAny generative architecture may be used, such as diffusion models, GANs, flow-based models, RNN-based generators, or signature-driven generative models, provided that the output aligns with the required sequence structure.\n\n**3. Dataset**\n\nThe dataset is constructed from daily foreign-exchange rates covering nearly two decades of global FX market activity.  \nRaw prices are transformed into log-returns to normalize scale, improve stationarity, and isolate incremental adjustments in exchange rates.\n\nThe time series is segmented using a window length of 24 and a stride of 2.  \nThis produces overlapping short-horizon sequences that capture behavioural patterns such as liquidity cycles, rate-differential adjustments, transitory risk-off episodes, and synchronous co-movements among major currencies.\n\nThe dataset includes:\n- Train set  \n- Validation set  \n- Test set  \n\nParticipants train models using the train and validation sets.  \nFinal ranking will be based exclusively on performance on the test set.\n\n**4. Evaluation**\n\nTo assess model performance, the following three metrics are used:\n\n- CrossCorrelationMetric  \n  Evaluates lagged cross-currency correlation structures, ensuring that generated sequences preserve synchronous and lead\u2013lag relationships between currency pairs.\n\n- AutoCorrelationMetric  \n  Measures autocorrelation patterns within each FX pair\u2019s return series, assessing whether the model reproduces short-run temporal dependencies, volatility clustering, and serial return behaviour.\n\n- MMDMetric  \n  Computes a kernel-based discrepancy between real and generated path distributions, capturing differences in joint distributional structure, temporal dynamics, and non-Gaussian features across the 24-step windows.\n\nCrossCorrelationMetric assesses cross-currency structure,  \nAutoCorrelationMetric assesses temporal behaviour,  \nand MMDMetric provides a comprehensive distributional comparison.\n\n**5. Success Criteria**\n\nA strong submission should:\n- Achieve low discrepancy on MMDMetric when comparing real and generated FX return sequences.  \n- Reproduce realistic cross-currency correlation structures as indicated by CrossCorrelationMetric.  \n- Preserve short-horizon autocorrelation and volatility patterns reflected in AutoCorrelationMetric.  \n- Generate stable sequences free of unrealistic drift, pathological noise amplification, or collapse.\n\n**6. Difficulty Level**\n\nDifficulty: Advanced\n\nModelling FX data requires learning rapidly evolving temporal patterns and capturing the joint structure of multiple exchange-rate processes.  \nThe 24-step horizon increases complexity by requiring precise modelling of short-run dynamics, cross-currency linkages, and high-frequency\u2013like behaviour within a daily dataset.",
        "task_type": "Generative modelling",
        "difficulty": "Advanced",
        "data_s3_key": "tasks/currency_generative/data/",
        "eval_fn_s3_key": "tasks/currency_generative/evaluation/"
    },
    {
        "task_id": "stock_forecast",
        "name": "Short-Horizon Multivariate Forecasting of U.S. Equity Log-Returns",
        "description": "Task: Short-Horizon Multivariate Forecasting of U.S. Equity Log-Returns\n\n**1. Task Overview**\n\nThis task evaluates a model\u2019s ability to forecast 5-day multivariate log-return sequences for eight major U.S. equities, using the preceding 20 days of market behaviour as input.  \nThe objective is to predict short-horizon equity dynamics informed by recent volatility regimes, sector interactions, and firm-specific return characteristics.\n\nTask Type: Forecasting  \nInput Shape: [20, 8] log-return sequences  \nTarget Shape: [5, 8] log-return sequences  \n\n**2. Task Description**\n\nParticipants must build a supervised forecasting model that takes as input 20 consecutive days of log-returns across the following equities:\naapl, amzn, goog, jnj, jpm, meta, msft, nvda.\n\nThe model must then predict the next 5 days of log-returns for the same set of equities.  \nEach supervised training sample therefore consists of:\n- an input window of shape [20, 8],  \n- a target window of shape [5, 8].  \n\nThe task focuses on short-horizon prediction where models must capture patterns such as:\n- typical one-month volatility evolution,  \n- reactions to corporate earnings or macroeconomic events,  \n- sector-specific spillovers,  \n- correlation structure among the equities.\n\nAny forecasting architecture may be used, including transformer-based models, sequence-to-sequence networks, temporal convolutional models, RNN variants, or regression-based baselines, as long as outputs match the required [5, 8] format.\n\n**3. Dataset**\n\nThe dataset consists of daily closing prices for eight large U.S. equities.  \nRaw prices are transformed into log-returns to normalize scale and stabilise variance across sectors.\n\nEach sample is produced using a 20-day input window and a 5-day prediction horizon.  \nThe dataset is already partitioned into:\n- Train set  \n- Validation set  \n- Test set  \n\nParticipants train and tune models on the train and validation sets.  \nFinal evaluation and ranking use only the test set.\n\n**4. Evaluation**\n\nForecast accuracy is evaluated using three metrics selected for short-horizon multivariate prediction:\n\n- RMSE  \n  Root mean squared error measuring magnitude accuracy of predicted log-returns.\n\n- MAE  \n  Mean absolute error providing a robust magnitude-based performance measure less sensitive to outliers.\n\n- QuantileLoss  \n  A pinball loss evaluating the accuracy of probabilistic or distributional forecasts at chosen quantiles, capturing tail risk and asymmetric forecast errors.\n\nRMSE and MAE quantify numerical forecasting accuracy,  \nwhile QuantileLoss measures performance in capturing forecast distributions and risk-sensitive deviations.\n\n**5. Success Criteria**\n\nA strong submission should:\n- Achieve low values on RMSE and MAE for the 5-day prediction horizon.  \n- Demonstrate strong QuantileLoss performance across quantiles of interest.  \n- Produce stable predictions without excessive noise, drift, or mode collapse.  \n- Capture short-horizon cross-sectional and temporal relationships that improve predictive reliability.\n\n**6. Difficulty Level**\n\nDifficulty: Intermediate\n\nAlthough the prediction horizon is short, effective models must learn sector interactions, volatility behaviour, and recent regime dynamics to produce high-quality forecasts across multiple equities simultaneously.",
        "task_type": "Forecasting",
        "difficulty": "Intermediate",
        "data_s3_key": "tasks/stock_forecast/data/",
        "eval_fn_s3_key": "tasks/stock_forecast/evaluation/"
    },
    {
        "task_id": "stock_generative",
        "name": "Multivariate Generative Modelling of Equity Log-Return Sequences",
        "description": "Task: Multivariate Generative Modelling of Equity Log-Return Sequences\n\n**1. Task Overview**\n\nThis task evaluates a model\u2019s ability to generate realistic 5-day multivariate log-return sequences for a set of major U.S. equities.\nThe objective is to reproduce short-horizon market behaviour, including sector-specific risk, cross-stock co-movements, and rapid responses to market news and sentiment.\n\nTask Type: Generative modelling  \nTrajectory Shape: [5, 8] log-return sequences  \n\n**2. Task Description**\n\nParticipants must build a generative model capable of producing realistic 5-day paths of daily log-returns across the following U.S. equities:\naapl, amzn, goog, jnj, jpm, meta, msft, nvda.\n\nEach data sample is a 5-day window of log-returns over these eight equities.  \nThe model must generate synthetic 5-day trajectories that exhibit similar distributional, temporal, and cross-sectional characteristics to the real sequences.\n\nSince the task focuses on short-horizon dynamics, models should capture the behaviour associated with week-long market cycles, including reactions to earnings reports, macroeconomic announcements, sector rotation, liquidity shocks, and changes in market sentiment.\n\nAny generative architecture may be used (for example, diffusion models, GANs, VAE-based models, normalizing flows, or signature-based models), as long as the generated output follows the required trajectory dimensions.\n\n**3. Dataset**\n\nThe dataset consists of daily closing prices for eight large publicly traded U.S. companies drawn from multiple sectors, representing a diverse cross-section of the equity market.  \nRaw prices are converted to log-returns to:\n- normalize scale differences across equities,  \n- improve stationarity, and  \n- reflect percentage changes in asset value.\n\nThe time series are segmented using windows of length 5 with a stride of 2.  \nThis design creates sequences that capture short-term market movements while keeping moderate overlap between windows to preserve statistical richness without excessive redundancy.\n\nThe dataset already includes:\n- Train set  \n- Validation set  \n- Test set  \n\nParticipants will train and tune models using the train and validation splits.  \nFinal ranking will be based solely on performance on the test set.\n\n**4. Evaluation**\n\nTo evaluate the fidelity of generated equity log-return sequences, three metrics are used:\n\n- CovarianceMetric  \n  Compares covariance matrices of real and generated samples, ensuring that models capture cross-sectional dependence structures, sector clustering, and co-movement patterns across equities.\n\n- AutoCorrelationMetric  \n  Measures the temporal autocorrelation profiles within each equity\u2019s log-return series, assessing whether short-term temporal dependencies, mean-reversion tendencies, and volatility persistence are reproduced.\n\n- MMDMetric  \n  Computes a kernel-based discrepancy between real and generated path distributions, capturing higher-order differences in shape, temporal structure, and short-horizon behaviour beyond simple summary statistics.\n\nCovarianceMetric evaluates cross-sectional structure,  \nAutoCorrelationMetric evaluates temporal structure,  \nand MMDMetric evaluates global distributional alignment of 5-day return paths.\n\n**5. Success Criteria**\n\nA strong submission should:\n- Achieve low discrepancy on MMDMetric when comparing real and generated 5-day sequences.  \n- Reproduce realistic cross-stock dependence patterns as reflected in CovarianceMetric.  \n- Match the short-horizon temporal dynamics of individual equities, indicated by AutoCorrelationMetric.  \n- Generate stable, non-degenerate samples that avoid mode collapse, excessive smoothing, or unrealistic volatility patterns.\n\n**6. Difficulty Level**\n\nDifficulty: Intermediate to Advanced\n\nThe short horizon reduces sequence length but increases sensitivity to fine-scale structure, requiring models to capture rapid market reactions, subtle cross-equity correlations, and realistic small-sample distributional behaviour within a generative modelling framework.",
        "task_type": "Generative modelling",
        "difficulty": "Intermediate to Advanced",
        "data_s3_key": "tasks/stock_generative/data/",
        "eval_fn_s3_key": "tasks/stock_generative/evaluation/"
    }
]