[
    {
        "task_id": "crypto_forecasting",
        "name": "Crypto Market Intraday Log-Return Forecasting",
        "task_type": "time-series-forecasting",
        "difficulty": "Intermediate",
        "description": "Task: Crypto Market Intraday Log-Return Forecasting\n\n**1. Task Overview**\n\nCryptocurrency markets operate continuously without circuit breakers or overnight closures. \nThis 24/7 environment, together with rapidly changing liquidity conditions, leads to pronounced \nshort-horizon volatility and shifting dependence structures across assets. Reliable intraday \nforecasting is therefore both challenging and practically important for risk monitoring, hedging, \nand algorithmic decision-making.\n\nThis task evaluates a model’s ability to forecast multivariate intraday log-return trajectories \nfor a small set of highly liquid cryptocurrencies. Participants must predict the near-future evolution \nof hourly log-returns, capturing volatility dynamics and cross-asset relationships under relatively \nstable macroeconomic conditions.\n\n**2. Task Description**\n\nParticipants are required to build and train a forecasting model that predicts the next 4 hourly \nlog-return steps for three major cryptocurrencies, conditioned on the preceding 20 hours of observed \nlog-returns.\n\nEach data sample represents one 24-hour window of hourly log-returns observed simultaneously across \nthe three assets. For forecasting, each 24-hour trajectory is split into an input context window \nconsisting of the first 20 hourly time steps, and a prediction target horizon consisting of the \nfinal 4 hourly time steps.\n\nModels should learn short-horizon temporal patterns (e.g., volatility clustering), handle noisy \nreturn dynamics, and preserve cross-asset dependence in the forecast horizon. Any forecasting \napproach may be used, including classical time-series models, machine learning methods, deep \nlearning sequence models, or hybrid approaches, provided that the outputs conform exactly to \nthe required format.\n\n**3. Dataset**\n\nThe dataset consists of historical hourly log-return data for three of the most actively traded \ncryptocurrencies, spanning multiple years. To reduce the impact of extreme market regimes, periods \nassociated with the COVID-19 crisis and large-scale quantitative easing have been excluded. \nThe time series are segmented into overlapping 24-hour samples using a rolling window approach.\n\nFor the forecasting task, participants are provided with the following pre-split NumPy datasets:\nTraining inputs: train_X.npy, shape [7150, 20, 3]\nTraining targets: train_Y.npy, shape [7150, 4, 3]\nTest inputs: test_X.npy, shape [1787, 20, 3]\n\nA held-out test target set (corresponding to the final 4 hours) is used for evaluation and is not \nprovided to participants. Final ranking is based solely on performance on this held-out test set \nusing all evaluation metrics.\n\n**4. Evaluation**\n\nForecast performance is evaluated using the following metrics:\n\n- RMSE\n  Root mean squared error measuring overall forecast accuracy.\n\n- MAE\n  Mean absolute error providing a stable magnitude-based measure.\n\n- MAPE\n  Mean absolute percentage error offering a scale-normalised comparison.\n\nEvaluation code for all metrics will be provided.\n\n**5. Submission**\n\nParticipants must return its forecasts as a JSON-serialized Python object (nested lists), \nrepresenting the prediction array. The file must contain model forecasts corresponding to \nthe test inputs and must have the shape [1787, 4, 3].\n\n**6. Difficulty Level**\n\nDifficulty: Intermediate",
        "data_url": "some_url",
        "eval_url": "https://raw.githubusercontent.com/JLanghamLopez/ts_bench/task_description/src/ts_bench/agents/ts_task_agent/eval_forecasting.py",
        "output_shape": [1787, 4, 3],
        "ground_truth_url": "some_url"
    },
    {
        "task_id": "equity_forecasting",
        "name": "Short-Horizon Forecasting of U.S. Equity Return–Volatility Dynamics",
        "task_type": "time-series-forecasting",
        "difficulty": "Easy",
        "description": "Task: Short-Horizon Forecasting of U.S. Equity Return–Volatility Dynamics\n\n**1. Task Overview**\n\nFinancial time series are characterised by non-stationarity, heavy tails, and complex \ncross-asset interactions. Even under regular market conditions, forecasting short-horizon \ndynamics of returns and volatility remains challenging due to low signal-to-noise ratios \nand evolving dependence structures.\n\nThis task focuses on short-horizon forecasting of multivariate financial time series under \nnormal market conditions. Participants are asked to predict the near-future evolution of \nreturn and volatility dynamics for multiple correlated U.S. equities, using recent historical \nobservations as input.\n\n**2. Task Description**\n\nIn this competition, participants are challenged to construct a forecasting model that \npredicts the next trading day’s return–volatility vector given the recent history.\n\nEach sample represents the joint daily return and volatility dynamics of five correlated \nU.S. equities over a short horizon. For forecasting, each trajectory is split into:\n\n- an input context window consisting of the first 4 daily observations, and\n- a prediction target horizon consisting of the final 1 daily observation.\n\nModels are expected to learn short-horizon temporal dependencies and cross-equity \nrelationships present in the data. Any forecasting approach may be used, including \nclassical time-series models, machine learning regressors, deep learning sequence models, \nor hybrid approaches, provided that outputs conform to the required format.\n\n**3. Dataset**\n\nParticipants are provided with preprocessed NumPy arrays corresponding to input–target \nsplits derived from historical financial time series under normal market conditions.\n\nTraining inputs: train_X.npy\nShape: [870, 4, 10]\nRepresents the first 4 daily observations of each training trajectory.\n\nTraining targets: train_Y.npy\nShape: [870, 1, 10]\nRepresents the next-day return and volatility values to be forecasted.\n\nTest inputs: test_X.npy\nShape: [217, 4, 10]\nRepresents the first 4 daily observations of each test trajectory.\n\nEach time step contains 10 features corresponding to daily return and volatility measures \nfor five correlated equities. The test targets are held out and used exclusively for evaluation.\n\n**4. Evaluation**\n\nForecast performance is evaluated using the following metrics:\n\n- RMSE\n  Root mean squared error measuring overall forecast accuracy.\n\n- MAE\n  Mean absolute error providing a stable magnitude-based measure.\n\n- MAPE\n  Mean absolute percentage error offering a scale-normalised comparison.\n\nEvaluation code for all metrics will be provided.\n\n**5. Submission**\n\nParticipants must return its forecasts as a JSON-serialized Python object (nested lists), \nrepresenting the prediction array. The file must contain model forecasts corresponding to \nthe test inputs and must have the shape of [217, 1, 10].\n\n**6. Difficulty Level**\n\nDifficulty: Easy\n",
        "data_url": "some_url",
        "eval_url": "https://raw.githubusercontent.com/JLanghamLopez/ts_bench/task_description/src/ts_bench/agents/ts_task_agent/eval_forecasting.py",
        "output_shape": [217, 1, 10],
        "ground_truth_url": "some_url"
    },
    {
        "task_id": "regime_switching_forecasting",
        "name": "Regime-switching Financial Time-Series Forecasting",
        "task_type": "time-series-forecasting",
        "difficulty": "Advanced",
        "description": "Task: Regime-switching Financial Time-Series Forecasting\n\n**1. Task Overview**\n\nThe limited availability of financial and economic data is a major bottleneck for the effective \napplication of machine learning methods in finance. Forecasting models trained on financial time \nseries must handle strong non-stationarity, low signal-to-noise ratios, and abrupt structural \nchanges that often reflect regime shifts such as periods of market stress.\n\nAccurate short- to medium-horizon forecasting of multivariate price–volatility dynamics is \nimportant for risk management, scenario analysis, and trading. In regime-switching environments, \nmodels must remain robust under both stable and elevated-volatility episodes and should preserve \ncross-asset relationships rather than fitting only marginal trends.\n\nThis task focuses on forecasting the near-future evolution of a multivariate financial system by \nlearning from historical trajectories that implicitly contain multiple market regimes.\n\n**2. Task Description**\n\nIn this competition, participants are challenged to construct a forecasting model that predicts \nthe next two time steps of a multivariate financial time series given the preceding history.\n\nEach sample trajectory represents the joint evolution of price and volatility processes for two \nfinancial instruments over 20 time steps. For the forecasting task, each trajectory is split into:\n\n- an input context window of the first 18 time steps, and\n- a prediction target horizon of the final 2 time steps.\n\nModels are expected to learn medium-horizon temporal structure, handle regime-dependent dynamics \n(without explicit regime labels), and preserve cross-variable and cross-asset dependence in their \nforecasts. Any forecasting approach may be used, including classical time-series models, machine \nlearning regressors, deep learning sequence models, or hybrid methods, provided that outputs conform \nto the required format.\n\n**3. Dataset**\n\nParticipants will be provided with pre-split NumPy datasets derived from the original regime-switching \ntrajectories. The original data consist of multivariate sample paths with shape [N, 20, 4], where each \ntrajectory contains 20 time steps, and 4 channels corresponding to price and volatility variables for \ntwo financial instruments.\n\nFor this forecasting task, the following the data are split into input–target pairs as follows:\n- Training inputs: train_X.npy with shape [20000, 18, 4]\n  The first 18 time steps of each training trajectory.\n\n- Training targets: train_Y.npy with shape [20000, 2, 4]\n  The final 2 time steps to be forecasted.\n\n- Test inputs: test_X.npy with shape [2000, 18, 4]\n  The first 18 time steps of each test trajectory.\n\nA held-out test target set (corresponding to the final 2 time steps) is used for evaluation and is not \nprovided to participants. Final ranking is based solely on performance on this held-out test set using \nall evaluation metrics.\n\n**4. Evaluation**\n\nForecast performance is evaluated using the following metrics:\n\n- RMSE\n  Root mean squared error measuring overall forecast accuracy.\n\n- MAE\n  Mean absolute error providing a stable magnitude-based measure.\n\n- MAPE\n  Mean absolute percentage error offering a scale-normalised comparison.\n\nEvaluation code for all metrics will be provided.\n\n**5. Submission**\n\nParticipants must return its forecasts as a JSON-serialized Python object (nested lists), \nrepresenting the prediction array. The file must contain model forecasts corresponding to \nthe test inputs and must have the shape [2000, 2, 4].\n\nA strong submission should:\n- Achieve low RMSE, MAE, and MAPE on the 2-day forecast horizon.\n- Produce stable forecasts without systematic drift or excessive noise.\n\n**6. Difficulty Level**\n\nDifficulty: Advanced\n\nAlthough the forecast horizon is short, the underlying trajectories exhibit regime-switching behaviour \nand heterogeneous volatility patterns. Successful models must generalise across both stable and stressed \nregimes and preserve multivariate dependence structures, making the task substantially more challenging \nthan standard stationary forecasting benchmarks.",
        "data_url": "some_url",
        "eval_url": "https://raw.githubusercontent.com/JLanghamLopez/ts_bench/task_description/src/ts_bench/agents/ts_task_agent/eval_forecasting.py",
        "output_shape": [2000, 2, 4],
        "ground_truth_url": "some_url"
    },
    {
        "task_id": "crypto_generation",
        "name": "Crypto Market Log-Return Simulation",
        "task_type": "time-series-generation",
        "difficulty": "Intermediate",
        "description": "Task: Crypto Market Log-Return Simulation\n\n**1. Task Overview**\n\nThis task evaluates a model’s ability to generate multivariate intraday log-return trajectories over a 24-hour horizon \nfor a small set of highly liquid cryptocurrencies. The objective is to model short-horizon return behaviour observed \nin continuous cryptocurrency markets, including volatility dynamics and cross-asset dependence, under relatively stable \nmacroeconomic conditions.\n\n**2. Task Description**\n\nParticipants are required to train a generative model that produces intraday log-return trajectories for three highly \ntraded cryptocurrencies. Each data sample represents one trading day and consists of 24 consecutive hourly log-returns \nobserved simultaneously across the three assets.\n\nThe training data are constructed using a rolling window approach applied to historical market data. Each window is \ntreated as an independent sample drawn from an unknown underlying distribution of daily return trajectories. \nThe modelling objective is to learn this distribution and to generate new synthetic samples that are indistinguishable \nfrom real data in terms of their statistical and temporal properties.\n\nAny generative modelling approach may be used, including diffusion-based models, GANs, flow-based models, autoregressive \ngenerators, or other sequence-based methods. Regardless of the modelling choice, generated outputs must have the exact \nshape [24,3] and reflect realistic intraday behaviour, including variability over time and dependence between assets.\n\n**3. Dataset**\n\nThe dataset consists of historical hourly log-return data for three of the most actively traded cryptocurrencies, \nspanning more than seven years. To reduce the impact of extreme market regimes, periods associated with the COVID-19 \ncrisis and large-scale quantitative easing have been excluded. The time series are segmented into overlapping 24-hour \nsamples using a rolling window approach. \n\nOnly the training dataset (train_log_return.npy) will be provided to participants, which has shape (7150, 24, 3). \nFinal evaluation is performed on the held-out test set using all evaluation metrics.\n\n**4. Evaluation**\n\nGenerated trajectories are evaluated by comparison with real test trajectories using the following metrics:\n\n- HistogramMetric\n  Measures the similarity between real and generated time series by comparing their empirical marginal distributions.\n\n- CrossCorrelationMetric\n  Evaluates whether dependence structures across different dimensions of the time series are preserved.\n\n- AutoCorrelationMetric\n  Assesses temporal dependence within individual time series components.\n\nEvaluation code for all metrics will be provided.\n\n**5. Submission**\n\nParticipants must return 1787 generated multivariate time series samples as a JSON-serialized Python object (nested lists) with shape [1787, 24, 3].\n\nA strong submission should:\n- Achieve low discrepancy on HistogramMetric on the test set.\n- Preserve cross-asset dependence as measured by CrossCorrelationMetric.\n- Match short-horizon temporal behaviour reflected by AutoCorrelationMetric.\n- Produce stable trajectories without obvious artefacts.\n\n**6. Difficulty Level**\n\nDifficulty: Intermediate\n\nThe task focuses on modelling short-horizon multivariate return dynamics for a small number of assets under relatively stable market conditions. While temporal and cross-sectional dependence must be captured, the reduced dimensionality and absence of regime extremes make the problem more accessible than large-scale, high-dimensional financial generative modelling tasks.",
        "data_url": "some_url",
        "eval_url": "https://raw.githubusercontent.com/JLanghamLopez/ts_bench/task_description/src/ts_bench/agents/ts_task_agent/eval_generation.py",
        "output_shape": [1787, 24, 3],
        "ground_truth_url": "some_url"
    },
    {
        "task_id": "equity_generation",
        "name": "Short-Horizon Generative Modelling of U.S. Equity Return–Volatility Dynamics",
        "task_type": "time-series-generation",
        "difficulty": "Easy",
        "description": "Task: Short-Horizon Generative Modelling of U.S. Equity Return–Volatility Dynamics\n\n**1. Task Overview**\n\nFinancial time series often exhibit non-stationarity, heavy tails, and complex temporal dependence, \nmaking realistic data-driven modelling a challenging task. In many practical applications, the availability \nof high-quality financial data is limited, which restricts the performance of downstream machine learning models.\n\nSynthetic data generation offers a promising solution by enabling the creation of artificial time series that \npreserve the statistical characteristics of real data while mitigating data scarcity and privacy concerns. \nThis task focuses on the unconditional generation of financial time series under regular market conditions.\nParticipants are asked to develop generative models that can produce realistic multivariate financial time series \nreflecting normal market dynamics, without conditioning on explicit regime labels.\n\n**2. Task Description**\n\nIn this competition, participants are challenged to construct and train an unconditional generative model capable of \nsimulating synthetic financial time series that closely approximate the distribution of real data observed under \nnormal market conditions.\n\nEach generated sample should represent the joint evolution of daily returns and volatility for multiple financial assets \nover a short time horizon. The objective is to reproduce realistic temporal dynamics and cross-asset relationships present \nin the training data.\n\nAny generative modelling approach may be used, including GANs, variational autoencoders, diffusion models, or other \nsequence-based generators, provided that the generated outputs match the required data format.\n\n**3. Dataset**\n\nThe dataset consists of historical financial time series representing daily return and volatility dynamics under normal \nmarket conditions. All samples corresponding to crisis periods have been removed to focus exclusively on regular market \nbehaviour. The time series represent the joint evolution of five correlated financial assets over a short horizon. \nEach sample corresponds to a fixed-length trajectory and is treated as an independent observation drawn from the underlying\ndata-generating process.\n\nOnly the training dataset will be provided to participants:\nFile: train.npy\nShape: [870, 5, 10]\nDescription:\n- 870 sample trajectories\n- 5 time steps per trajectory (daily observations)\n- 10 features per time step, corresponding to return and volatility measures for the 5 assets\n\nFinal evaluation is performed on the held-out test set using all evaluation metrics.\n\n**4. Evaluation**\n\nGenerated trajectories are evaluated by comparing samples from the model to real test trajectories using the following metrics:\n\n- HistogramMetric\n  Measures the similarity between real and generated time series by comparing their empirical marginal distributions.\n\n- CrossCorrelationMetric\n  Evaluates whether dependence structures across different dimensions of the time series are preserved.\n\n- AutoCorrelationMetric\n  Assesses temporal dependence within individual time series components.\n\nEvaluation code for all metrics will be provided.\n\n**5. Submission**\n\nParticipants must return 217 generated multivariate time series samples as a JSON-serialized Python object (nested lists) with shape [217, 5, 10].\n\nA strong submission should:\n- Achieve low discrepancy on HistogramMetric on the test set.\n- Preserve cross-equity dependence patterns.\n- Match short-term temporal behaviour observed in the data.\n- Produce stable trajectories without artefacts or mode collapse.\n\n**6. Difficulty Level**\n\nDifficulty: Easy\n",
        "data_url": "some_url",
        "eval_url": "https://raw.githubusercontent.com/JLanghamLopez/ts_bench/task_description/src/ts_bench/agents/ts_task_agent/eval_generation.py",
        "output_shape": [217, 5, 10],
        "ground_truth_url": "some_url"
    },
    {
        "task_id": "regime_switching_generation",
        "name": "Regime-switching Financial Time-Series Generation",
        "task_type": "time-series-generation",
        "difficulty": "Advanced",
        "description": "Task: Regime-switching Financial Time-Series Generation\n\n**1. Task Overview**\n\nThe limited availability of financial and economic data is a major bottleneck for the effective application of \nmachine learning methods in finance. High-fidelity synthetic data generation provides a promising approach to \naugment existing datasets while preserving statistical properties and protecting data privacy. Recent advances \nin generative modelling, including GANs, VAEs, and diffusion-based models, have shown strong potential in this area.\n\nFinancial time series exhibit distinctive challenges, such as strong time heterogeneity, low signal-to-noise ratios, \nand abrupt structural changes. In particular, asset price and volatility dynamics often behave very differently \nuring periods of market stress compared to economically stable regimes. These regime shifts are commonly associated \nwith events such as financial crises, pandemics, or major policy interventions.\n\nThis task focuses on developing generative models that can faithfully reproduce multivariate financial time series\nexhibiting regime-switching behaviour. Robust solutions are expected to capture both normal and high-volatility \nregimes and the transitions between them.\n\n\n**2. Task Description**\n\nIn this competition, participants are challenged to construct a generative model capable of producing synthetic\nfinancial time series that closely mimic the joint distribution of price and volatility processes for multiple \nfinancial instruments.\n\nThe training data consist of short multivariate trajectories that reflect different market regimes, including \nlow-volatility and high-volatility episodes. These regimes are not explicitly labelled; instead, regime characteristics \nmust be inferred implicitly from the observed dynamics. Participants may employ any generative modelling approach, \nincluding but not limited to GAN-based models, variational autoencoders, diffusion models, or other sequence-based \ngenerators. Generated samples should reproduce realistic temporal dynamics, cross-variable relationships, and \nregime-dependent behaviour observed in the real data.\n\n**3. Dataset**\n\nThe participants will be provided with the training dataset (train.npy) It consists of 20,000 sample trajectories, \neach representing the joint evolution of price and volatility for two financial instruments over a fixed time horizon.\n\nTraining Dataset shape:[20000, 20, 4]\n\nInterpretation:\n- 20 time steps per trajectory\n- 4 channels corresponding to price and volatility variables for the two assets\n\nThe dataset exhibits heterogeneous dynamics arising from different market regimes, including periods of elevated \nvolatility and more stable behaviour. No explicit regime labels are provided.\n\nFinal ranking is based solely on performance on the held-out test set using all evaluation metrics.\n\n**4. Evaluation**\n\nModels will be evaluated by comparing generated trajectories to real test trajectories using three metrics:\n\n- HistogramMetric\n  Measures the similarity between real and generated time series by comparing their empirical marginal distributions.\n\n- CrossCorrelationMetric\n  Evaluates whether dependence structures across different dimensions of the time series are preserved.\n\n- AutoCorrelationMetric\n  Assesses temporal dependence within individual time series components.\n  \nEvaluation metric code for all three metrics will be provided to participants.\n\n**5. Submission**\n\nParticipants must submit their generated samples as a JSON-serialized Python object (nested lists) representing the synthetic time series array.\n\nThe submission must have the following shape: [2000, 20, 4]\n\nA successful submission should:\n- Achieve low discrepancy on HistogramMetric on the test set.\n- Preserve cross-commodity temporal dependence patterns reflected by CrossCorrelationMetric.\n- Match temporal persistence and volatility characteristics measured by AutoCorrelationMetric.\n- Produce stable and realistic trajectories without obvious artefacts or mode collapse.\n\n**6. Difficulty Level**\n\nDifficulty: Advanced\n",
        "data_url": "some_url",
        "eval_url": "https://raw.githubusercontent.com/JLanghamLopez/ts_bench/task_description/src/ts_bench/agents/ts_task_agent/eval_generation.py",
        "output_shape": [2000, 20, 4],
        "ground_truth_url": "some_url"
    }
]
